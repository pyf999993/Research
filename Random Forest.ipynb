{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc4e7a3-ffc0-42f2-be55-4306cc62d834",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.utils import parallel_backend\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import csv\n",
    "import plotly as py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202a0cee-0aa1-4dc9-9193-fa29c8344d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv(\"Mixed toxicity modeling.csv\", sep=\",\", header=0)\n",
    "y = data.iloc[:, -1]\n",
    "X = data.iloc[:, 1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbef6daa-b1ac-4bce-88be-5a8d5eadbd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and testing sets\n",
    "bins = np.linspace(0, 1.4, 14)\n",
    "y_binned = np.digitize(y, bins)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y_binned, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253d5fc0-a6b7-4a52-ac29-ae509c65b801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Random Forest model\n",
    "model = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a75d5f-86d6-4ea1-9f56-bd530d5609e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 10-fold cross-validation\n",
    "scores = cross_val_score(model, X_train, y_train, cv=10, scoring='r2', error_score='raise')\n",
    "print(f'Mean R^2 score: {np.mean(scores)}')\n",
    "print(f'Standard deviation: {np.std(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd7041d-490c-4fa3-81e0-5ae8be4cef85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter range\n",
    "n_estimators_range = [100, 200, 300, 400]\n",
    "max_depth_range = [70, 80, 90, 100]\n",
    "max_depth_range.append(None)\n",
    "min_samples_split_range = [2, 5, 10]\n",
    "min_samples_leaf_range = [2, 4, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a57ee5-5c7c-489b-b022-9c1d0ccc5f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': n_estimators_range,\n",
    "    'max_depth': max_depth_range,\n",
    "    'min_samples_split': min_samples_split_range,\n",
    "    'min_samples_leaf': min_samples_leaf_range\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b877fd2-e7e8-4cfe-9af5-dd4bae81a41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for hyperparameter tuning\n",
    "grid_search = GridSearchCV(model, param_grid, cv=10, scoring='neg_mean_squared_error')\n",
    "with parallel_backend('multiprocessing', n_jobs=-1):\n",
    "    grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f177b558-9255-443e-9f0f-1c0d678d8068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output best parameters and score\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "print(\"Best Score: \", -grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0cb97c-d717-488a-b585-598cbcecfc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model using best parameters\n",
    "best_model = RandomForestRegressor(**grid_search.best_params_)\n",
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb97d88-697e-4c49-8eea-8e476ed5b21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance on training set\n",
    "scores = cross_val_score(best_model, X_train, y_train, cv=10)\n",
    "std_error = np.std(scores / np.sqrt(len(scores)))\n",
    "print(\"Standard Error: \", std_error)\n",
    "print(\"CV Score: \", np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f11745-40fa-417b-bcf7-170873420542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d146c12-ce90-4d04-afb7-e69388fecb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Mean Squared Error and RMSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Mean Squared Error: \", mse)\n",
    "print(\"Root Mean Squared Error: \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30739b7-434a-47ba-b18f-e2c307f7c2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate R^2 and adjusted R^2 scores\n",
    "test_score = r2_score(y_test, y_pred)\n",
    "n = len(y_test)\n",
    "k = X_test.shape[1]\n",
    "adjusted_r2 = 1 - ((1 - test_score) * (n - 1) / (n - k - 1))\n",
    "print(f'Test Set R^2 Score: {test_score}')\n",
    "print(f'Adjusted R^2 Score: {adjusted_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f36253e-1eb7-4237-91ab-59ea64b93740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save output to CSV\n",
    "output_matrix = np.concatenate((y_test.values.reshape(-1, 1), y_pred.reshape(-1, 1)), axis=1)\n",
    "output_df = pd.DataFrame(output_matrix, columns=['y_test', 'y_pred'])\n",
    "output_df.to_csv(\"RandomForest_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8038b2fa-b5c6-4812-919e-123c670d855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SHAP and Plotly\n",
    "shap.initjs()\n",
    "py.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855a7249-3e69-4170-949b-be3af1fa01cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for SHAP\n",
    "X_display = pd.DataFrame(X_test.values, columns=X_test.columns, index=X_test.index)\n",
    "background_data = shap.maskers.Independent(X_train)\n",
    "explainer = shap.Explainer(best_model, background_data)\n",
    "shap_values = explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67673fa1-6d4d-404d-b345-b2fa71304046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate SHAP summary plot\n",
    "plt.figure(dpi=300, figsize=(20, 10))\n",
    "shap.summary_plot(shap_values, X_display, show=False, max_display=20)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.savefig(\"RandomForest_shap_summary_plot.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbccd4c-8195-42e4-9351-585cf3fa32a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate SHAP bar plot\n",
    "plt.figure(dpi=500, figsize=(20, 10))\n",
    "shap.plots.bar(shap_values, max_display=21, show=False)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.savefig(\"RandomForest_shap_bar_plot.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace4763a-d876-406b-bd10-8898d7a67096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average SHAP values\n",
    "shap_values_matrix = shap_values.values\n",
    "feature_names = X_test.columns.tolist()\n",
    "shap_means = np.mean(np.abs(shap_values_matrix), axis=0)\n",
    "shap_dict = dict(zip(feature_names, shap_means))\n",
    "with open('RandomForest_shap_values_mean.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['feature', 'shap_mean'])\n",
    "    for key, value in shap_dict.items():\n",
    "        writer.writerow([key, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9690c04f-8a84-4d7c-ad1e-354067cdac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Compute distance matrix and standardized residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60808441-71d8-455b-83fa-6944237277fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "def normalize_data(A):\n",
    "    A_min = A.min(axis=0)\n",
    "    A_max = A.max(axis=0)\n",
    "    return (A - A_min) / (A_max - A_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcacb96-2629-4f2e-919d-0aaf6803d8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-score normalization\n",
    "def z_score_normalize(data):\n",
    "    means = np.mean(data, axis=0)\n",
    "    std_devs = np.std(data, axis=0)\n",
    "    return (data - means) / std_devs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7921585-128d-4425-9f0a-1f7366eb63c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Euclidean distances\n",
    "def euclidean_distances(A):\n",
    "    return np.sqrt(np.sum((A[:, np.newaxis, :] - A[np.newaxis, :, :]) ** 2, axis=2))\n",
    "\n",
    "def average_distances_to_all_points(A):\n",
    "    dist_matrix = euclidean_distances(A)\n",
    "    sum_distances = np.sum(dist_matrix, axis=1)\n",
    "    average_distances = sum_distances / (A.shape[0] - 1)\n",
    "    return average_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4afb9c-2220-4d3b-a984-8cacc6f81c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute standardized residuals for training set\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "residuals = y_train - y_train_pred\n",
    "standardized_residuals_z = z_score_normalize(residuals)\n",
    "np.savetxt(\"RandomForest_train_standardized_residuals.csv\", standardized_residuals_z, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81ce331-b4e8-4524-9125-b9825aee969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute training set distance matrix\n",
    "A = X_train.values\n",
    "A_normalized = z_score_normalize(A)\n",
    "avg_dists_to_all_normalized = average_distances_to_all_points(A_normalized)\n",
    "np.savetxt(\"RandomForest_Train_avg_diststances_to_all.csv\", avg_dists_to_all_normalized, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c0ecb8-8a33-48ea-ae62-290f63dd1a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average distances from test set to training set\n",
    "def euclidean_distances(A, B):\n",
    "    A_np = A.to_numpy() if isinstance(A, pd.DataFrame) else A\n",
    "    B_np = B.to_numpy() if isinstance(B, pd.DataFrame) else B\n",
    "    return np.sqrt(np.sum((A_np[:, np.newaxis, :] - B_np[np.newaxis, :, :]) ** 2, axis=2))\n",
    "\n",
    "def average_distances_from_B_to_A(A, B):\n",
    "    dist_matrix = euclidean_distances(A, B)\n",
    "    sum_distances = np.sum(dist_matrix, axis=0)\n",
    "    average_distances = sum_distances / A.shape[0]\n",
    "    return average_distances\n",
    "\n",
    "B_normalized = z_score_normalize(X_test)\n",
    "average_distances_from_B_to_A = average_distances_from_B_to_A(X_train, B_normalized)\n",
    "np.savetxt(\"RandomForest_test_average_distances_from_B_to_A.csv\", average_distances_from_B_to_A, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33f5869-2255-4b9f-b224-d6148eaa7299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute standardized residuals for test set\n",
    "test_residuals = y_pred - y_test\n",
    "test_standardized_residuals_z = z_score_normalize(test_residuals)\n",
    "np.savetxt(\"RandomForest_test_standardized_residuals.csv\", test_standardized_residuals_z, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
