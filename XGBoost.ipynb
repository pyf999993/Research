{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bdd924-decd-4112-be1e-ebd2f5e0412c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils import parallel_backend\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import plotly as py\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb98edde-7f9c-44e0-bdb1-3fc499571b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv(\"Mixed toxicity modeling.csv\", sep=\",\", header=0)\n",
    "y = data.iloc[:, -1]\n",
    "X = data.iloc[:, 1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42ebac6-0f15-4d2d-b4dc-b2d2a828aebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and testing sets\n",
    "bins = np.linspace(0, 1.4, 14)\n",
    "y_binned = np.digitize(y, bins)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y_binned, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91df84d4-8021-4b5c-8cbe-ff9397391fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff86c42-3e37-440f-bd1a-a5424b27859e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 10-fold cross-validation\n",
    "scores = cross_val_score(model, X_train, y_train, cv=10, scoring='r2', error_score='raise')\n",
    "print(f'Mean R^2 score: {np.mean(scores)}')\n",
    "print(f'Standard deviation: {np.std(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5162bf5b-b487-48f8-bcc3-3296a87ddfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [700, 800, 900],\n",
    "    'max_depth': [2, 3, 4],\n",
    "    'learning_rate': [0.1, 0.2, 0.3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e50cf26-9e08-4db6-af57-a4adb7d126ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(model, param_grid, cv=10, scoring='neg_mean_squared_error')\n",
    "with parallel_backend('multiprocessing', n_jobs=-1):\n",
    "    grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f93ffe-c2d3-4c5c-b17a-3e5e587d2ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output best parameters and score\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "print(\"Best Score: \", -grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b77b82-bfbe-4f0b-bfe0-d644f0b025ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model using best parameters\n",
    "best_model = xgb.XGBRegressor(**grid_search.best_params_)\n",
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2054d487-efbb-4566-b0fa-ae41d0ca2a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance on training set\n",
    "scores = cross_val_score(best_model, X_train, y_train, cv=10)\n",
    "std_error = np.std(scores / np.sqrt(len(scores)))\n",
    "print(\"Standard Error: \", std_error)\n",
    "print(\"CV Score: \", np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb8c9f7-803a-49d4-8093-f9d63a43ab7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce223fc9-1789-41ce-81de-4bf7e361d4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Mean Squared Error and RMSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35e6c7a-acc5-4aa8-9aad-9983c094a3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate R^2 and adjusted R^2 scores\n",
    "test_score = r2_score(y_test, y_pred)\n",
    "n = len(y_test)\n",
    "k = X_test.shape[1]\n",
    "adjusted_r2 = 1 - ((1 - test_score) * (n - 1) / (n - k - 1))\n",
    "print(f'Test Set R^2 Score: {test_score}')\n",
    "print(f'Adjusted R^2 Score: {adjusted_r2}')\n",
    "print(\"Mean Squared Error: \", mse)\n",
    "print(\"Root Mean Squared Error: \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d0770e-7fee-4d66-ac87-5b96ac288b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save output to CSV\n",
    "output_matrix = np.concatenate((y_test.values.reshape(-1, 1), y_pred.reshape(-1, 1)), axis=1)\n",
    "output_df = pd.DataFrame(output_matrix, columns=['y_test', 'y_pred'])\n",
    "output_df.to_csv(\"XGBoost_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e082c34-238f-48b2-ad9e-1d46089b2ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SHAP and Plotly\n",
    "shap.initjs()\n",
    "py.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cbf447-d602-4351-8c86-eaaccd3aa68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for SHAP\n",
    "X_display = pd.DataFrame(X_test.values, columns=X_test.columns, index=X_test.index)\n",
    "background_data = shap.maskers.Independent(X_train)\n",
    "explainer = shap.Explainer(best_model, background_data)\n",
    "shap_values = explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fede7fd9-c72d-46ca-b53b-6483a8fdb956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate SHAP summary plot\n",
    "plt.figure(dpi=300, figsize=(20, 10))\n",
    "shap.summary_plot(shap_values, X_display, show=False, max_display=20)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.savefig(\"XGBoost_shap_summary_plot.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880691e1-599a-4c75-8904-c3953cf2ad82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate SHAP bar plot\n",
    "plt.figure(dpi=500, figsize=(20, 10))\n",
    "shap.plots.bar(shap_values, max_display=21, show=False)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.savefig(\"XGBoost_shap_bar_plot.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2810214e-5249-450c-9baa-e577f38588da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average SHAP values\n",
    "shap_values_matrix = shap_values.values\n",
    "feature_names = X_test.columns.tolist()\n",
    "shap_means = np.mean(np.abs(shap_values_matrix), axis=0)\n",
    "shap_dict = dict(zip(feature_names, shap_means))\n",
    "with open('XGBoost_shap_values_mean.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['feature', 'shap_mean'])\n",
    "    for key, value in shap_dict.items():\n",
    "        writer.writerow([key, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180f1f7a-78e6-4b2d-bfca-00b150851a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Compute distance matrix and standardized residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059703db-3b0f-4f2a-a591-62584c0f459e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "def normalize_data(A):\n",
    "    A_min = A.min(axis=0)\n",
    "    A_max = A.max(axis=0)\n",
    "    return (A - A_min) / (A_max - A_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e94acf6-699c-40f6-84fc-abbf0f189b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-score normalization\n",
    "def z_score_normalize(data):\n",
    "    means = np.mean(data, axis=0)\n",
    "    std_devs = np.std(data, axis=0)\n",
    "    return (data - means) / std_devs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca67c58b-54f0-48a2-bf8d-c91e3d935944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Euclidean distances\n",
    "def euclidean_distances(A):\n",
    "    return np.sqrt(np.sum((A[:, np.newaxis, :] - A[np.newaxis, :, :]) ** 2, axis=2))\n",
    "\n",
    "def average_distances_to_all_points(A):\n",
    "    dist_matrix = euclidean_distances(A)\n",
    "    sum_distances = np.sum(dist_matrix, axis=1)\n",
    "    average_distances = sum_distances / (A.shape[0] - 1)\n",
    "    return average_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac3c63f-2af9-48bb-8883-4042ca2c8bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute standardized residuals for training set\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "residuals = y_train - y_train_pred\n",
    "standardized_residuals_z = z_score_normalize(residuals)\n",
    "np.savetxt(\"XGBoost_train_standardized_residuals.csv\", standardized_residuals_z, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eae0890-a76b-4200-a8ac-f05ccc0918b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute training set distance matrix\n",
    "A = X_train.values\n",
    "A_normalized = z_score_normalize(A)\n",
    "avg_dists_to_all_normalized = average_distances_to_all_points(A_normalized)\n",
    "np.savetxt(\"XGB_Train_avg_distances_to_all.csv\", avg_dists_to_all_normalized, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a2744d5-b89f-409a-a2d4-e49c363985d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average distances from test set to training set\n",
    "def euclidean_distances(A, B):\n",
    "    A_np = A.to_numpy() if isinstance(A, pd.DataFrame) else A\n",
    "    B_np = B.to_numpy() if isinstance(B, pd.DataFrame) else B\n",
    "    return np.sqrt(np.sum((A_np[:, np.newaxis, :] - B_np[np.newaxis, :, :]) ** 2, axis=2))\n",
    "\n",
    "def average_distances_from_B_to_A(A, B):\n",
    "    dist_matrix = euclidean_distances(A, B)\n",
    "    sum_distances = np.sum(dist_matrix, axis=0)\n",
    "    average_distances = sum_distances / A.shape[0]\n",
    "    return average_distances\n",
    "\n",
    "B_normalized = z_score_normalize(X_test)\n",
    "average_distances_from_B_to_A = average_distances_from_B_to_A(X_train, B_normalized)\n",
    "np.savetxt(\"XGBoost_test_average_distances_from_B_to_A.csv\", average_distances_from_B_to_A, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e74a63-a663-47ad-95d1-1d61f950616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute standardized residuals for test set\n",
    "test_residuals = y_pred - y_test\n",
    "test_standardized_residuals_z = z_score_normalize(test_residuals)\n",
    "np.savetxt(\"XGBoost_test_standardized_residuals.csv\", test_standardized_residuals_z, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
